{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Recognition Using Convolutional Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.2, # For randomly applying shearing transformations\n",
    "                                  zoom_range=0.2, # For randomly zooming inside pictures\n",
    "                                  horizontal_flip=True, # For randomly flipping half of the images horizontally\n",
    "                                  rotation_range=40, # A value in degrees (0-180), a range within which to randomly rotate pictures\n",
    "                                  width_shift_range=0.2, # For randdomly rotating pictures\n",
    "                                  height_shift_range=0.2, \n",
    "                                  fill_mode='nearest' # The strategy used for filling in newly created pixels after a transformation\n",
    "                                 )\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\"D:/RT4/PFA/dataset/test\", batch_size=1, \n",
    "                                                        class_mode='categorical', \n",
    "                                                       )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Classifier():\n",
    "    def __init__(self, train_folder=\"dataset/train\", validation_folder=\"dataset/test\", \n",
    "                  inshape=(50,50,3), num_classes=2, num_train=21, num_validation=8):\n",
    "        self.train_folder = train_folder\n",
    "        self.validation_folder =  validation_folder\n",
    "        self.inshape = inshape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_train = num_train\n",
    "        self.num_validation = num_validation\n",
    "        \n",
    "    def model(self, learning_rate=0.001):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Convolution2D(filters=32,\n",
    "                                kernel_size=(3, 3),\n",
    "                                strides=(1, 1), \n",
    "                                input_shape=self.inshape, \n",
    "                                data_format=\"channels_last\")\n",
    "                 )\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "        model.add(Convolution2D(filters = 16,\n",
    "                                kernel_size=(3, 3),\n",
    "                                strides=(1, 1)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(200))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, batch_size=128, epochs=12, learning_rate=0.001, model_file=\"my_model.h5\", refine = False):\n",
    "        \n",
    "        # The augmentation configuration used for training\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                            shear_range=0.2, \n",
    "                                            zoom_range=0.2, \n",
    "                                            horizontal_flip=True, \n",
    "                                            rotation_range=40,  \n",
    "                                            width_shift_range=0.2,\n",
    "                                            height_shift_range=0.2, \n",
    "                                            fill_mode='nearest' \n",
    "                                          )\n",
    "\n",
    "        # The augmentation configuration used for testing (rescale only)\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        # A generator that will read pictures found in subfolers of 'data/train' \n",
    "        # and indefinitely generate augmented image data\n",
    "        train_generator = train_datagen.flow_from_directory(self.train_folder,  \n",
    "                                                            target_size=(50,50),  \n",
    "                                                            batch_size=batch_size, \n",
    "                                                           )\n",
    "        # Similar generator for validation data\n",
    "        validation_generator = test_datagen.flow_from_directory(self.validation_folder, \n",
    "                                                                target_size=(50,50),\n",
    "                                                                batch_size=batch_size, \n",
    "                                                               )\n",
    "        \n",
    "        # Create labels file\n",
    "        dict_label = train_generator.class_indices\n",
    "        dict_label = {v: k for k, v in dict_label.items()}\n",
    "        with open('labels.pkl', 'wb') as f:\n",
    "            pickle.dump(dict_label, f)\n",
    "        \n",
    "        if refine:\n",
    "            model = load_model(model_file)\n",
    "        else:\n",
    "            model = self.model(learning_rate=learning_rate)\n",
    "        \n",
    "        model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=self.num_train // batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=self.num_validation // batch_size)\n",
    "        \n",
    "        # Saving the model\n",
    "        model.save(model_file)\n",
    "        \n",
    "        \n",
    "    def predict(self, x, model_file=\"my_model.h5\"):\n",
    "        model = load_model(model_file)\n",
    "        prediction = model.predict(x)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_DIM = 300\n",
    "W_DIM = 300\n",
    "\n",
    "im_classifier = Image_Classifier(train_folder =\"dataset/train\",\n",
    "                                 validation_folder = \"dataset/test\", \n",
    "                                 inshape=(H_DIM,W_DIM,3),\n",
    "                                 num_classes=2,\n",
    "                                 num_train=1000,\n",
    "                                 num_validation=200)\n",
    "\n",
    "im_classifier.train(batch_size=2,\n",
    "                    epochs=20,\n",
    "                    learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"dataset/test/Skander_Meghirbi/SkanderMeghirbi21.JPG\")\n",
    "im = im.resize((H_DIM,W_DIM), Image.ANTIALIAS)\n",
    "im = np.array(im)\n",
    "im = np.expand_dims(im, axis=0)\n",
    "\n",
    "im_classifier = Image_Classifier()\n",
    "\n",
    "prediction = im_classifier.predict(im, model_file=\"my_model.h5\")\n",
    "pred_idx = prediction[0].argmax()\n",
    "\n",
    "with open('labels.pkl', 'rb') as f:\n",
    "            dict_label = pickle.load(f)\n",
    "\n",
    "print(\"The corresponding person is \", dict_label[pred_idx], \"with probability of %d\", prediction[0][pred_idx]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
